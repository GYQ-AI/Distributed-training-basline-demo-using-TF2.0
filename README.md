# Distributed-training-basline-demo-using-TF2.0
This work is to create a runnable distributed training basline across multi-gpus with the purpose of accelerating the construction of any larger or more complex distributed deep learning projects on Tensorflow 2.0. 
A Grab-and-Go demo has been provided, please check script files and experimental snapshots (as below) for more details. 


Distributed training and validation records:

![Screenshot from 2021-06-10 15-06-23](https://user-images.githubusercontent.com/82304993/123392074-3d666780-d5cf-11eb-8b13-5768f8eb3105.png)



Training and testing process:

![Training and testing process](https://user-images.githubusercontent.com/82304993/123393597-d184fe80-d5d0-11eb-8610-400550341f65.png)



Status of GPUs:

![nvidia-smi](https://user-images.githubusercontent.com/82304993/123392094-40f9ee80-d5cf-11eb-9b34-87d40f4e30b8.png)
